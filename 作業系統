作業系統重點
 

ALU（算术逻辑单元）和 GPU（图形处理单元）是计算机体系结构中的两个不同的组件，它们在功能和设计上有很大的区别。
1.	ALU（算术逻辑单元）：
•	定义： ALU是中央处理单元（CPU）中的一个核心组件，负责执行算术和逻辑运算。它执行诸如加法、减法、逻辑与、逻辑或等基本算术和逻辑运算。
•	用途： ALU主要用于执行计算任务，处理整数和浮点数的基本运算。它是CPU中的关键组件，执行大多数指令。
2.	GPU（图形处理单元）：
•	定义： GPU是专门设计用于图形处理和并行计算的处理器。它包含大量的小处理单元，用于同时处理大量数据，尤其是在图形渲染和科学计算中。
•	用途： GPU的主要用途是加速图形处理，例如在游戏、计算机辅助设计（CAD）和视频渲染中。除此之外，由于其并行处理能力，GPU也被广泛用于科学计算和深度学习等领域。
比较：
•	设计目标： ALU的设计目标是执行通用的算术和逻辑运算，而GPU的设计目标是加速图形渲染和并行计算。
•	并行性： GPU在设计上强调大规模并行性，具有多个处理单元，可以同时处理多个数据。ALU通常更专注于单一任务的执行。
•	数据处理： ALU主要处理通用的整数和浮点数计算，而GPU在图形处理中更专注于向量和矩阵运算，以及在并行计算中执行大规模的浮点数操作。
•	用途： ALU是CPU的一部分，用于执行程序中的通用计算任务。GPU则专注于图形渲染和并行计算，适用于需要大规模并行性的应用。
 



控制单元（Control Unit）是计算机中的一个核心组件，属于中央处理单元（CPU）的一部分。它负责协调和控制CPU内部各个部件的操作，以及执行指令的顺序。控制单元的主要功能是从存储器中读取指令、解码指令并执行对应的操作，以使计算机能够完成所需的任务。
主要职责和功能包括：
1.	指令获取（Instruction Fetch）： 控制单元从内存中获取存储在程序计数器指定位置的指令。
2.	指令解码（Instruction Decode）： 控制单元对获取的指令进行解码，确定该指令要执行的操作。
3.	执行操作（Execution）： 控制单元根据解码的指令执行相应的操作，可能涉及到算术和逻辑运算、数据传输等。
4.	时序控制（Timing Control）： 控制单元确保各个操作在正确的时间序列中执行，以保证计算机的稳定运行。
5.	分支控制（Branch Control）： 处理条件分支和无条件分支指令，决定程序计数器的跳转。
6.	异常处理（Exception Handling）： 处理中断和异常，确保在出现特殊情况时能够适当地转移控制。
7.	状态维护（State Maintenance）： 控制单元维护CPU内部状态的正确性，包括标志寄存器和其他状态信息。
控制单元与算术逻辑单元（ALU）一起协同工作，以执行指令中的操作。控制单元的设计取决于计算机体系结构，不同的体系结构可能有不同的指令集和控制单元结构。它是计算机执行程序的关键部分，确保指令按照正确的顺序和时序执行，从而实现计算和数据处理。

CPU执行周期包括以下阶段：
1.	取指令阶段（Fetch）： 从内存中取得下一条机器指令。
2.	指令解码阶段（Decode）： 对取得的指令进行解码，确定需要执行的操作。
3.	执行阶段（Execute）： 执行指令中的操作，可能涉及算术运算、逻辑运算等。
4.	访存阶段（Memory Access）： 如果指令需要访问内存，则在此阶段进行内存读取或写入操作。
5.	写回阶段（Write Back）： 将执行结果写回到寄存器或内存。

………………………………………………………………..
Batch system
Multiprogramming
Time sharing
Multiprocessing
Distributed sys
Real time sys
Handheld sys


多元程式規劃
Offline
Buffering(cpu bond job /io bond job)
Spooling
Caching


i/o處理方式
polling io
interrupt io
DMA

硬體保護
Io保護
Memory保護(monitor area protection/user program area protection)
Cpu保護

作業系統接收訊息
命令直譯器
系統呼叫(sys call)

Kernel

vm


行程
Program vs process

行程狀態

行程控制表

排班佇列:
工作佇列
就緒佇列
裝置佇列

排班佇列種類
長期排班程式
短程排班程式
中期排班程式

Cpu scheduling algo(說明優缺比較)
CPU调度的主要目的是有效地利用CPU资源，提高系统的性能和响应时间。以下是CPU调度的一些主要目的：
1.	提高CPU利用率： CPU调度的核心目标之一是确保CPU尽可能地保持忙碌，避免因某些进程等待而导致CPU空闲。通过选择合适的进程来执行，系统可以更充分地利用CPU资源。
2.	减少等待时间： CPU调度致力于减少进程等待CPU执行的时间，以提高系统的响应时间。选择高优先级的进程或采用其他调度算法，可以降低进程等待CPU的时间，使系统更加敏捷。
3.	提高系统吞吐量： 通过合理调度进程，系统可以达到更高的吞吐量，即在单位时间内完成的进程数量。有效的调度算法可以确保系统同时执行多个进程，从而提高整体系统性能。
4.	公平性： CPU调度还追求公平性，确保每个进程都有机会获得CPU时间。公平的调度可以防止某个进程长时间占用CPU资源，导致其他进程无法得到执行的情况。
5.	避免饥饿和死锁： CPU调度要避免进程因资源不足而陷入饥饿状态，确保所有进程都有机会执行。此外，一些调度算法还可以帮助预防死锁的发生。
6.	响应时间优化： 对于交互式系统，即时响应对用户体验至关重要。CPU调度可以通过合理选择进程，使得对用户输入的响应更为迅速。
7.	先来先服务（First-Come, First-Served，FCFS）：
1.	描述： 按照进程到达就绪队列的顺序进行调度。先到达的进程先被执行。
2.	优点： 简单，易于实现。
3.	缺点： 长作业可能导致短作业等待时间过长（"Convoy Effect"），无法适应不同作业的执行时间差异。
8.	最短作业优先（Shortest Job Next，SJN）或最短作业优先（Shortest Job First，SJF）：
1.	描述： 选择下一个执行的进程时，选择估计执行时间最短的进程。
2.	优点： 最小化平均等待时间，适用于批处理系统。
3.	缺点： 无法预知作业的实际执行时间，可能导致长作业一直等待。
9.	轮转调度（Round Robin，RR）：
1.	描述： 每个进程被分配一个时间片（时间量），当时间片用完后，切换到下一个就绪队列中的进程。
2.	优点： 公平，适用于分时系统。
3.	缺点： 可能导致上下文切换开销过大，响应时间相对较长。
10.	优先级调度：
1.	描述： 给每个进程分配一个优先级，选择下一个执行的进程时，选择具有最高优先级的进程。
2.	优点： 可以根据任务的重要性分配优先级。
3.	缺点： 可能导致低优先级的进程长时间等待，优先级反转问题。
11.	多级反馈队列调度（Multilevel Feedback Queue，MLFQ）：
1.	描述： 将就绪队列划分为多个级别，每个级别具有不同的优先级，进程根据其行为在不同队列中移动。
2.	优点： 适应性强，能够处理不同类型的进程。
3.	缺点： 调整参数需要谨慎，复杂度较高。
12.	短作业剩余时间优先（Shortest Remaining Job First，SRJF）：
1.	描述： 在每次选择下一个执行的进程时，选择剩余执行时间最短的进程。
2.	优点： 有效地减小平均等待时间，对批处理系统有良好的性能。
3.	缺点： 需要预测进程的剩余执行时间，可能导致长作业一直等待。
13.	多级队列调度（Multilevel Queue Scheduling）：
1.	描述： 将就绪队列划分为多个独立的队列，每个队列具有不同的优先级。通常，较高优先级队列的进程先执行，如果队列为空，则执行较低优先级队列中的进程。
2.	优点： 简单、灵活，适应性强，可以根据进程的属性分配到不同队列。
3.	缺点： 不够灵活，可能导致长时间等待高优先级队列的进程。
 

"Starvation"（饥饿）问题通常出现在某些特定的调度算法或策略中，导致某些进程或任务无法获得执行的机会。以下是一些可能导致饥饿问题的调度方法和一些不容易导致饥饿的方法：
有可能导致饥饿的调度方法：
1.	优先级调度： 如果所有进程都具有较高优先级的进程存在，低优先级的进程可能长时间等待，导致饥饿问题。这种情况下，高优先级的进程会占据CPU，而低优先级的进程得不到执行机会。
2.	多级队列调度（MLFQ）： 如果有大量的进程在高优先级队列中，而低优先级队列中的进程一直无法获得执行机会，也可能导致饥饿。这可能发生在系统调整队列切换的策略不当的情况下。
不容易导致饥饿的调度方法：
1.	先来先服务（FCFS）： FCFS 调度方法通常是公平的，每个进程都按照它们到达就绪队列的顺序执行。但是，如果有长作业占据CPU，其他进程可能需要长时间等待。
2.	轮转调度（RR）： 轮转调度会给每个进程分配一个时间片，确保每个进程都有机会执行。虽然可能存在等待时间较长的问题，但不容易导致饥饿，因为每个进程都会轮流执行。
3.	多级反馈队列调度（MLFQ）的合理实现： 在合理设置队列切换的条件和时间片的情况下，MLFQ 调度也可以避免饥饿问题。


Thread
Thread vs process
1.	程序（Program）：
•	定义： 程序是一组指令和数据的集合，是静态的，未执行的代码文件。
•	生命周期： 程序存在于磁盘或其他存储媒体上，直到被加载到内存并执行为止。
2.	进程（Process）：
•	定义： 进程是正在运行的程序的实例，包括执行时所需的指令、数据、和系统资源。
•	生命周期： 进程具有动态的生命周期，包括创建、执行、终止等阶段。
3.	线程（Thread）：
•	定义： 线程是在进程内执行的独立执行单元，共享进程的资源，包括内存和文件句柄等。
•	生命周期： 线程的生命周期依赖于所属的进程，多个线程可以共享相同的资源。
 

Thread種類
Thread pool







Deadlock
1.	死锁（Deadlock）：
•	定义： 死锁是指两个或多个线程或进程彼此等待对方释放资源，而导致所有线程或进程都无法继续执行的状态。
•	典型情景： 常见于多个线程或进程同时持有某些资源，并且试图获取其他线程或进程持有的资源。如果没有适当的资源释放机制或资源请求的顺序导致循环等待，可能发生死锁。
2.	活锁（Livelock）：
•	定义： 活锁是指线程或进程在避免死锁的过程中，由于不断重试导致一直无法取得进展的状态。
•	典型情景： 当多个线程或进程试图解决冲突或争夺资源时，它们可能会不断重试，但由于竞争条件或争夺的资源一直不可用，它们无法继续执行，形成了活锁。
关键区别：
•	死锁是线程或进程等待彼此释放资源的状态，导致所有线程或进程无法继续执行。
•	活锁是线程或进程在解决冲突或竞争资源时，由于不断重试而无法取得进展。
 cp
達成條件
處理方式

記憶體管理
Memory allocation strategy:
First fit
Best fit
Worst fit
Next fit
常發生的問題與解決方式


虛擬記憶體(vm)
1.	Virtual Memory (虚拟内存):
•	定义： 虚拟内存是一种操作系统的内存管理技术，允许程序访问一个比实际物理内存更大的地址空间。它通过将部分数据存储到硬盘上，以便在需要时进行交换，从而扩展了计算机的可用内存。在虚拟内存系统中，每个进程都有其私有的虚拟地址空间，而不受物理内存的限制。
•	用途： 虚拟内存的主要目的是提供更大的地址空间，使得多个进程能够共存，并且在需要时能够有效地使用磁盘作为辅助存储。
2.	Virtual Machine (虚拟机):
•	定义： 虚拟机是一种在计算机上模拟硬件和操作系统的软件实体。它提供了一个独立的、隔离的运行环境，允许在同一物理计算机上运行多个虚拟操作系统。每个虚拟机被视为一个独立的计算机，具有自己的操作系统和应用程序。
•	用途： 虚拟机的主要用途是在一台物理计算机上运行多个操作系统或应用程序，实现资源的有效共享和隔离。虚拟

 
在计算机系统中，虚拟内存是一种操作系统使用的技术，它允许程序访问一个比实际物理内存更大的地址空间。虚拟内存的一个重要功能是将不常用的数据从物理内存中移出，以便给其他数据或程序腾出空间。这允许执行比实际物理内存更大的程序，就像你描述的情况，一个12GB的程序在8GB的实际物理内存中执行。
以下是实现这种情况的一些关键概念：
1.	分页机制： 操作系统使用分页机制将程序和数据划分为固定大小的页面（通常为4KB）。这样，只有程序中当前需要的部分被加载到物理内存中。
2.	虚拟内存地址空间： 每个进程都有其自己的虚拟内存地址空间，通常是一个很大的地址范围，超过实际物理内存大小。这使得程序可以使用比物理内存更大的地址范围。
3.	页面置换： 当程序访问虚拟内存中的某个页面时，如果该页面不在物理内存中，操作系统将负责将其加载到物理内存中。如果物理内存已满，操作系统需要选择哪些页面从物理内存中移出，以便为新页面腾出空间。这个过程被称为页面置换。
4.	硬盘上的页面文件： 如果程序的虚拟内存中的某些部分不常用，它们可以被写入到硬盘上的页面文件中。当程序再次访问这些部分时，它们可以从页面文件中被重新加载到物理内存中。
在你描述的情况下，如果一个12GB的程序在8GB的实际物理内存中执行，操作系统可能会通过以下方式来实现：
•	将程序和数据划分为页面，并根据需要将页面加载到物理内存中。
•	对于不常用的页面，将其写入到硬盘上的页面文件中。
•	在程序执行过程中，根据需要进行页面置换，确保当前执行的部分在物理内存中。
需要注意的是，虽然虚拟内存提供了更大的地址空间，但当程序访问的页面不在物理内存中时，会引入一定的性能开销，因为需要从硬盘加载页面。因此，尽量避免过多的页面置换是设计高效程序的重要考虑因素


Demand paging
Thrashing

磁碟管理
Free space management
Allocation methods
RAID
RAID（Redundant Array of Independent Disks）是一种通过将多个硬盘驱动器组合在一起形成一个逻辑存储单元的技术，用于提高数据存储的性能、可靠性和/或容量。RAID系统可以通过将数据划分和复制到多个硬盘上，实现对数据的冗余和并行存储，从而提供更好的性能和容错能力。


 
•	读性能： RAID 0、RAID 5、RAID 6 和 RAID 10 在读性能方面通常较好，因为它们能够并行读取数据。
•	写性能： RAID 0 和 RAID 10 在写性能方面较好，而 RAID 5 和 RAID 6 的写性能相对较差，因为写操作需要计算奇偶校验信息。
冗余性：
•	RAID 1、RAID 5、RAID 6 和 RAID 10 提供了某种形式的冗余，允许在硬盘故障时保持数据可用。
•	RAID 0 没有冗余，一个硬盘故障将导致数据丢失。
容错能力：
•	RAID 1、RAID 5、RAID 6 和 RAID 10 具有一定的容错能力，能够在硬盘故障时继续提供服务。
•	RAID 0 没有容错能力，一个硬盘故障将导致数据不可用。
•	RAID 2： 位级条带化，使用海明码纠错，可通过错误检测和纠错来恢复数据，对磁盘的访问是并行的，但由于需要额外的硬件支持，实际中很少使用。
•	RAID 3： 字节级条带化，带奇偶校验，通过奇偶校验信息在单个硬盘故障时进行数据恢复，适用于大块数据的读操作。
•	RAID 4： 块级条带化，带奇偶校验，类似于 RAID 3，但是数据和奇偶校验信息存储在不同的硬盘上，适用于大块数据的读操作，对随机写操作性能较差。






////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
deadlock
定義:是指两个或多个进程（线程）互相等待对方释放资源才能继续执行的状态。在死锁状态下，进程无法继续运行，导致系统停滞
特性:
1. mutual exclusion: 一次只有一個process可以使用資源
2. hold & wait: 一個process持有某些資源且等大其他process擁有的資源
3. no preemption: 資源只能被持有的process自己放棄，其他process無法搶占
4. circular wait: 環狀等待

解決方法:
Deadlock Prevention: 確保 deadlock 不會發生 => 4 個條件其中一個不成立
Mutual exclusion:
對 sharable resources 而言，Mutual exclusion 一定成立
而 nonsharable resources，因為可以同時讀取相同檔案，所以一定不會產生
但很困難讓他不成立

Hold and Wait:
process 必須保證一個行程在要求一項資源時，不可以佔用任何其它的資源
兩種可能策略
允許 process 在執行之初可先持有部分資源，一旦要申請新資源，則必須先釋放持有的全部資源，才可以提申請
除非 process 可以一次取得完成工作所需的全部資源，才允許 process 持有資源，否則不准持有任何資源
低資源利用率
可能會有 starvation

No preemption:
變成 preemption
process 可以搶奪 waiting process 所持有的 Resource
解決：採取類似”Aging”技術(將被搶奪的次數，列為提高優先權之依據)

Circular Wait:
確保循環式等候的條件不成立，我們對所有的資源型式強迫安排一個線性的順序
作法
給予每個 Resource 唯一的(unique)資源編號(ID)
規定 process 需依資源編號遞增的方式提出申請
優點:保證系統絕不會有死結存在

Deadlock Avoidance
當 process 提資源申請(Request)時，則 OS 需依據下列資訊：

系統目前可用的資源數量(Available)
各 process 對資源的最大需求量(max)
各 process 目前持有的資源量(allocation) 各系統還需多少資源(need) = max - allocation
執行 Banker’s Algorithm(內含 Safety Algorithm)判斷系統若核准後，是否處於 Safe state，若是，則核准申請，否則(處於 unsafe state)，則否決此次申請，Process 則等待依段時間後再重新申請

缺點:resource 可用率低、throughput 低


deadlock detection
偵測死結是否存在 若死結存在，則必須打破死結，恢復正常的機制

優點：resource utilization 較高，Throughput 高
缺點：cost 太高
////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

作業系統型態　http://debussy.im.nuu.edu.tw/sjchen/OS/97Spring/Ch_1.pdf
1. batch system
將相同或類似的工作整批集中處理，並於完成後全部送回，無法與使用者互動，通常為自動化程式
通常為離線作業，非急迫且週期性的工作

2. multiprogramming
通時運行多個程序，程序為在cpu上交替運行一段時間，透過快速切換來實現同時運行多個程序

3.mutlliprocessing
同時在多個處理器上運行程序，每個處理器都有自己的cpu與memory，可獨立並行執行任務
Symmetric(對稱): 每個處理器功能相同
Asymmetric(非對稱): 功能不同

Note: 處理系統區別在於它使用多個獨立的處理器，每個處理器都能執行自己的指令和程序，而多程式系統僅使用一個處理器以分時方式執行多個程序

4. time sharing
Time-sharing（分時系統）和Multiprogramming（多程式系統）是兩種不同的作業系統技術，它們有著以下主要差異：

執行概念：

Time-sharing：分時系統允許多個用戶共享單個計算機系統，每個用戶都獲得較小的時間片來使用CPU，以達到同時多用戶執行程序的效果。
Multiprogramming：多程式系統允許同時運行多個程序，但一次只有一個程序使用CPU。程序之間通過快速切換（稱為上下文切換）來共享CPU資源。
優先級和時間分配：

Time-sharing：分時系統根據不同的優先級分配時間片給每個用戶，通常較高優先級的用戶獲得更長的時間片，而低優先級的用戶獲得較短的時間片。
Multiprogramming：多程式系統通常使用循環方式分配處理時間給不同程序，每個程序獲得固定的時間片，當時間片用完後，CPU切換到下一個程序。
資源共享和效能：

Time-sharing：分時系統主要關注多用戶之間的資源共享和服務品質（如響應時間），並根據優先級和時間片進行調度，以提供良好的用戶體驗。
Multiprogramming：多程式系統更注重資源的最大利用和效能，通過在不同程序之間快速切換以提高CPU利用率，並通過同時執行多個程序來提高時間利用率。

5.distributed system
透過網路將分散在不同地方的處理器串聯，分為peer to peer與主從式架構
Hadoop spark

6.real-time system
因對速度講究，輔助的儲存媒體很少用(vitual memory)，大部分程式儲存於ROM(READ ONLY MEMORY)









改善CPU閒置的方法
1.	OFFLINE
用TAPE做媒介，CPU可同時做INPUT OUTPUT

2.	BUFFERING
Input: 避免cpu直接面對memory，用memory做媒介
Output: 避免cpu直接面對printer，用memory做媒介
Note:
i/o bound: 執行速度受限於i/o device，需大量i/o作業及少量cpu運算
cpu bonud: 執行速度受限於CPU，需大量CPU運算作業及少量i/o作業

3.	SPOOLING
Input: 避免cpu直接面對tape，用disk做媒介
Output: 避免cpu直接面對printer，用disk做媒介
優點:
Io與cpu可同時運行
效率更高
可遠端io運作

Note: spooling與buffer不同處
Buffering（緩衝）：

定義：Buffering是一種將數據暫時存儲在緩衝區中的技術，以平衡不同組件的處理速度。當數據流向不同的組件時，緩衝區可以用來調節數據的傳送速率，以確保數據在組件之間以恰當的速度傳輸。
差別：Buffering用於調節或平衡數據流之間速度不匹配的情況。它可以在數據的傳輸過程中使用緩衝區暫時存儲數據，以便在接收方準備好之前保持數據的完整性和連續性。
Spooling（排隊處理）：

定義：Spooling是一種將數據、作業或其他任務暫存到磁盤或其他存儲設備的技術。它將多個不同的數據源或作業組合成一個共享的佇列，並按順序或優先級從佇列中進行處理。
差別：Spooling主要用於解決在多個輸入源和輸出源之間的競爭和衝突問題。它將不同來源的數據或作業暫時存儲在共享的佇列中，然後按照順序或優先級將它們送到目的地進行處理。


4.	CACHING
將經常使用的data儲存於cache memory中

快取記憶體寫回策略
Write through: cpu寫資料回快取，同時寫回memory
資料有一致性，但因要寫回mem所以速度較慢
Write back: cpu把寫回memory的動作延遲，指修正快取中的資料，一段時間後再寫回memory
速度快，但有可能出現資料不一致的現象



i/o處理方式
透過system call(monitor call)觸發中斷
硬體產生的中斷:interrupt
軟體: trap
觸發時系統會進入monitor mode

Polling：CPU設定I/O命令後，會步算監測I/O運作的STATUS，效率差
Interrupt-driven I/O：CPU與I/O可同時運作，當I/O完成時發出I/O COMPLETE中斷通知OS，OS收到INTERRUPT後暫停目前工作執行ISR轉移資料至memory
DMA(Direct Memory Access)：由i/o device controller負責memory與i/o之間資料傳輸，cpu無須參與，透過cycle stealing，cpu 與 dma controller可同時運作


Command Interpreter 命令直譯器
Def: 接收 user 輸入命令, 加以判別：
正確 => 呼叫對應的 “Command procedure”
不正確 => Output error
分為:
Intergrated part of O.S. => command procedure 整合到 O.S. 之中
優點：速度快 (因為所有 command procedure 已於 O.S., 故在 Monitor Area (Memory) 之中)
缺點：可擴充性低 (彈性差)
Isolated part of O.S. => 將 command procedure 獨立於 O.S. 之外
優點：可擴充性佳 (彈性好)
缺點：速度較慢 (因為可能需做 I/O <-> Memory 的傳輸)



System call（系統呼叫）是一種在作業系統中使用的機制，它允許用戶程序與作業系統進行交互和訪問作業系統提供的服務或功能。當用戶程序需要執行特權操作或訪問受保護的資源時，它必須通過系統呼叫來執行這些操作。

Kernel 核心程式
負責多個 process 運作上的協調, 管理等
負責底層 Hardware 資源的分配及管理
分為：巨核心 和 微核心(unix)

Virtual Machine 虛擬機器
Def: 藉由模擬技術, 創造一份與底層硬體完全一致的 copy (複製), 以達 Virtual Machine 之效
可利用資源共享的技術產生許多 Virtual Machine:
CPU Scheduling => 共享 CPU
用 “Virtual Memory” => 共享 Memory Space
用 Spooling => 共用 I/O Device
優缺:安全、適合開發測試 / 製作難、系統間溝通困難

java garabage collection: 對於不再被物件使用的記憶體重新取回並交還給系統



Program 意旨軟體工程師在 IDE、editor等所寫的程式碼(code)，也就是說還尚未load入記憶體的 code，我們稱之為Program

Process 意旨已經執行並且 load 到記憶體中的 Program ，程序中的每一行程式碼隨時都有可能被CPU執行
以下條列幾點 Process 的觀念 —

Process 是電腦中已執行 Program 的實體。
每一個 Process 是互相獨立的。
Process 本身不是基本執行單位，而是 Thread (執行緒)的容器。
Process 需要一些資源才能完成工作，如 CPU、記憶體、檔案以及I/O裝置。

thread 在同一個 Process 中會有很多個 Thread ，每一個 Thread 負責某一項功能
以下條列幾點 Thread 的觀念 —

同一個 Process 會同時存在多個 Thread。
同一個 Process 底下的 Thread 共享資源，如 記憶體、變數等，不同的Process 則否。
在多執行緒中(Multithreading)，兩個執行緒若同時存取或改變全域變數(Global Variable)，則可能發生同步(Synchronization，恐龍本第六章)問題。若執行緒之間互搶資源，則可能產生死結
thread 會將變數保存在記憶體空間中，稱作 stack

process 是 OS 分配資源的最小單位，而 thread 則是作業系統能夠進行運算排程的最小單位，也就是說實際執行任務的並不是進程，而是進程中的線程

process/thread pool
進（線）程池：預先建立好，帶有一堆進程的隊列，有需要時就進去拿，而不用重新建立，以此增加效能並減少執行時的延遲。
之所以要開多個 process 或 thread 常是因為要「並行運算」或做 I/o 處理
透過進程池可以幫助我們管理 process，並減少建立和結束 process 的資源消耗
同一個時間下，一個進程只會被分配到一顆 CPU 工作，假設進程池設 4 個，但只有一個 CPU，那基本上同一時間內最多只會有一個進程在工作

cpu scheduling
1. fifo: 先來先做
2. sjf : 所需執行時間越少越優先
3. round robin: 所有process皆使用固定的執行時間，超過此時間跳入下一個process等待下次循環



記憶體管理
Contiguous Memory Allocation可以又可以分為兩種

Fixed-partition: 把每個類型的程式所需要的記憶體都先切好存放的位置，一但程式被執行起來要load進記憶體的時候就直接放進去相對應類行的空間。比較舊也相對單純的方法，方便實作且容易理解。
Variable-size:以動態的方式去決定Proess要被放進去哪個記憶體空間，程式被執行起來load進記憶體的時候才開始找一個夠大的空間塞進去。比較複雜，但可以節省更多的記憶體空間。
找記憶體空間放進去的方法又分為三種

First-fit : 第一個找到空間夠大的就放進去
Best-fit : 只找到大小剛好的或者最小卻剛好夠的，但可能會有壞處就是造成了剩下一點小小的別人也無法使用
Worst-fit : 找空間最大的記憶體區段來放入
比較多人使用First-fit來搜索記憶體空間，因為Best-fit和Worst-fit在尋找的複雜度是很高的，First-fit相對快速且單純。


Fragmentation
當我們在配置記憶體給Process時，並不會配得剛剛好，會是以一個單位一個單位的大小在配置空間，那這樣的情況下，記憶體空間一定會有浪費，Fragmentation指的就是被浪費掉的零碎的空間:

External fragmentation: 在程式外面的空間夠多，但卻沒有一個夠大去融入下一個Process的狀況，會發生在variable-size allocation的情況下。
Internal fragmentation: 切給proess的memory不一定會全部用完，在fixed-size allication的情況下發生。

Non-Contiguous Memory Allocation
Non-Contiguous的概念下，每個Process所使用的記憶體是凌亂的分布在記憶體的區段之中，其中有一套機制去為每個Process管理其記憶體，其中最關鍵的是有一個Hash Table(Page Table)，去儲存logical address 與 physical address的對應關係。

這麼做就會有許多的好處

使用者以為空間是連續的，實際上是non-contiguous的。
透過這樣子的映射關係，可以實作Share memory讓Process交換資料，以及dynmaic linking去使用同一個library。

segmentation paging的意義:
1. 程式由許多segments組成，segment再以page進行memory allocation降低外部破碎



虛擬記憶體

虛擬記憶體 (Virtual Memory) 會讓應用程式認為其擁有連續可用的記憶體（一個連續完整的位址空間），而實際上，其通常是被分隔成多個實體記憶體碎片，還有部分暫時儲存在外部磁碟記憶體上，需要時才進行資料交換。

優點：

允許程式大小大於實體記憶體 (physical memory) 大小情況下，程式仍然能執行。 
OS 的負擔，程式設計師無負擔。
記憶體的各個小空間皆有機會被利用到，記憶體使用度上升。
提高 multiprogramming degree，提昇 CPU 使用度。
每一次的 I/O transfer time 下降，因為不用將整個程式的所有 page 載入。(然而載入整個程式很耗費 I/O transfer time，因為總傳輸次數變多。)


實現 Virtual Memory 方法：Demand Paging

以 paging 為基礎，採用 lazy swapper 技巧。即程式執行之初不將全部的 pages 載入 memory，僅載入執行所須的 pages，如要處理 page fault 問題，由 OS 另行處理。
當 page fault 發生且 memory 無可用 page 時，則 OS 必須執行 page replacement。OS 必須選擇一個 victim page，將其 swap out 到 disk 來空出一個可用 frame，再將 lost page swap in 到此 frame。


Thrashing 現象：

若 Process 分配到的 frame 不足，則會經常發生 page fault，此時必須執行 page replacement。
若採用 global replacement policy，則此 process 會替換其它 process 的 page 以空出 frame，造成其它 process 也會發生 page fault，而這些 process 也會去搶其它 process 的 frame，造成所有 process 皆在處理 page fault。
所有 process 皆忙於 swap in/out，造成 CPU idle。(CPU idle 時 OS 會企圖引進更多的 process 進入系統讓 Thrashing 現象更嚴重。)

Thrashing的解決方法：

1. 降低 multiprogramming degree

2. 利用 page fault ratio 控制來防止 thrashing
3. 利用 working set model



磁碟管理
raid種類
RAID 0：
RAID 0通常稱為條帶化（Striping），它將數據均勻地分散存儲在兩個或更多的硬碟上，通過同時存取多個硬碟提高數據讀寫性能。RAID 0具有較高的讀寫速度，但沒有容錯能力，如果一個硬碟失效，則所有存儲在RAID 0陣列中的數據都將丟失。

RAID 1：
RAID 1被稱為鏡像（Mirroring），它使用兩個硬碟將數據重複地存儲在兩個硬碟上，提供了數據的冗餘備份。RAID 1具有優秀的容錯能力，即使一個硬碟失效，數據仍然可以通過另一個硬碟還原。然而，RAID 1的實際容量只是硬碟容量的一半。

RAID 5：
RAID 5組合了條帶化和分佈式奇偶校驗（Distributed Parity）的特點。它將數據進行條帶化存儲，同時使用奇偶校驗位來提供容錯能力。RAID 5至少需要三個硬碟，並且可以容忍一個硬碟的失效。當一個硬碟失效時，RAID 5可以通過奇偶校驗位重建失效的數據。RAID 5提供了良好的讀取性能，但寫入性能稍低。

RAID 6：
RAID 6在RAID 5的基礎上添加了第二個奇偶校驗位，提供更高的容錯能力。RAID 6至少需要四個硬碟，可以容忍兩個硬碟的同時失效。RAID 6提供了良好的容錯能力和數據保護，但相對於RAID 5，寫入性能稍低。


系統程式
Assembler（組譯器）：
Assembler是一種將低階語言（通常是組合語言）轉換成機器碼的程式。它將源代碼中的組合語言指令轉換成可執行的機器指令，以供計算機硬體執行。

Linker（連結器）：
Linker是將獨立編譯的目標文件（Object file）結合在一起，並解析符號引用，生成可執行文件或動態鏈接庫的工具。Linker將目標文件中未解析的符號引用與其他目標文件中的符號定義相關聯，以解決符號解析問題。

Loader（載入器）：
Loader是一個將可執行文件從存儲器載入到計算機主存中並準備執行的軟體程式。它負責處理機器碼和數據的載入、內容的初始化、地址的重定位等任務，以使程序可以正常運行。

Compiler（編譯器）：
Compiler是一種將高階語言（如C、C++等）源代碼轉換成低階語言（如機器碼）的軟體工具。Compiler將高階語言的源代碼編譯成中間碼或機器碼，以便計算機硬體能夠執行。

Interpreter（解譯器）：
Interpreter是一種在運行時逐行解釋並執行高階語言源代碼的工具。它將源代碼逐行解析，並立即執行指令，無需編譯生成可執行檔。Interpreter通常會進行語法檢查、運行時錯誤檢測和記憶體管理等工作。

Macro Processor（巨集處理器）：
Macro Processor是一種在進行編譯前對源代碼中的巨集進行處理的軟體工具。它擁有自定義的巨集定義和巨集展開規則，使得程式設計師能夠撰寫簡潔且可重複使用的代碼，並在編譯過程中將其展開或替換成實際的源代碼。

***
Compiler和Interpreter是兩種常見的程式語言處理器。以下是Compiler和Interpreter之間的比較：

執行方式：

Compiler：編譯器將整個程式碼轉換成機器碼（或其他目標語言），生成可執行文件。這個可執行文件可以單獨運行，且無需再次編譯。
Interpreter：解譯器通常一次解譯和執行源代碼的一行程式碼。它逐行解析並直接執行程式碼。
執行效率：

Compiler：編譯器將整個源代碼轉換成機器碼，運行時效率較高。因為它僅需將程式碼編譯一次，而不需要每次運行時進行解譯或編譯。
Interpreter：解譯器逐行解析和執行程式碼，因此每行程式碼的執行都需要花費時間，且相對於編譯器效率較低。
調試和錯誤處理：

Compiler：由於編譯器在執行之前已經對整個程式碼進行了檢查和轉換，因此編譯器通常提供較好的錯誤檢測和調試能力。
Interpreter：解譯器在運行時逐行解釋和執行程式碼，因此在執行到某行程式碼時才能檢測到錯誤。
可移植性：

Compiler：由於編譯器生成的是機器碼或目標語言，它們可以在不同的平台上運行，具有較好的可移植性。
Interpreter：解譯器需要在每個平台上都存在，並根據該平台的架構運行源代碼，所以相對於編譯器，可移植性較低。
開發速度：

Compiler：編譯器需要將整個程式碼轉換成機器碼，它的編譯過程較長。
Interpreter：解譯器可以逐行解釋和執行程式碼，因此在開發階段可以立即執行，提供更快的開發速度。

***

Macro（巨集）和Subroutine（子程序）是兩種常見的程式設計概念，用於重複使用程式碼段落。以下是Macro和Subroutine之間的比較：

Macro（巨集）：

定義：Macro是一段被命名且可重複使用的程式碼段，可以通過使用巨集處理器來在程式中展開。展開後的程式碼可以看作是原始程式碼的插入。
擴展：巨集在巨集處理器扮演一個擴展的角色，展開後的程式碼直接插入到調用的地方。
可定製性：使用巨集，可以通過定義和參數化來定製程式碼，從而產生不同的結果。
讀取和展開：巨集處理器讀取和展開巨集指令，將原始的巨集指令替換為其相應的程式碼片段。
Subroutine（子程序）：

定義：Subroutine是一段具有名稱的程式碼，可在程式中多次調用，以執行指定的功能或操作。它被看作是一個獨立的程式碼段，有自己的進入點和返回點。
調用和返回：Subroutine在調用時執行，然後返回到調用的地方。調用方和被調用方之間有明確的調用和返回關係。
參數傳遞：Subroutine可以接受參數，並返回結果。它可以使用參數進行計算和操作，並將結果返回給調用者。
比較結論：

定義方式：Macro是一段被命名且可重複使用的程式碼段，而Subroutine是一段具有名稱的程式碼，可被調用和返回。

展開和調用方式：Macro在巨集處理器的幫助下，在程式內部展開和插入，Subroutine通過調用和返回來執行。

定製性：Macro可以通過定義和參數化來定製程式碼，而Subroutine可以接受參數進行計算和操作。

可讀性：Subroutine通常比Macro更容易閱讀和理解，因為它更直觀地表達了程式的結構和邏輯。
